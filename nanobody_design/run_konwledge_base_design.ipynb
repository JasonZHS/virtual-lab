{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345b9b10-a8ac-40bc-b16c-2751743e92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE, CREATIVE_TEMPERATURE\n",
    "from virtual_lab.prompts import (\n",
    "    CODING_RULES,\n",
    "    REWRITE_PROMPT,\n",
    "    create_merge_prompt,\n",
    ")\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import load_summaries\n",
    "\n",
    "from knowledge_base_constants import (\n",
    "    background_prompt,\n",
    "    num_iterations,\n",
    "    num_rounds,\n",
    "    discussions_phase_to_dir,\n",
    "    principal_investigator,\n",
    "    team_members,\n",
    "    scientific_critic,\n",
    "    tech_lead,\n",
    "    biomedical_ontologist,\n",
    "    data_scientist,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2915138-4375-4915-8a85-731781eb246d",
   "metadata": {},
   "source": [
    "## Team selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba2418d-f796-4136-ab0a-ede5124d5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team selection - prompts\n",
    "team_selection_agenda = f\"\"\"{background_prompt}\n",
    "TASK: Define 3 distinct Agents to form the AlzKB Implementation Team.\n",
    "\n",
    "OUTPUT FORMAT: Python `Agent()` objects ONLY. No conversational filler.\n",
    "Do not include yourself.\n",
    "TEMPLATE:\n",
    "Agent(\n",
    "    title=\"Principal Investigator (Alzheimer's KG)\",\n",
    "    expertise=(\n",
    "        \"Lead scientist specializing in Alzheimer's Disease (AD) data integration. \"\n",
    "        \"Expert in constructing heterogeneous Knowledge Graphs connecting clinical phenotypes, \"\n",
    "        \"neuroimaging features, genetic biomarkers (e.g., APOE), and tau/amyloid pathology.\"\n",
    "    ),\n",
    "    role=(\n",
    "        \"1. Define rigorous schemas aligning with standard ontologies (e.g., SNOMED CT, Gene Ontology). \"\n",
    "        \"2. Direct the Tech Lead to prioritize high-confidence data sources (e.g., ADNI, AMP-AD). \"\n",
    "        \"3. Review extraction pipelines for precision over recall to prevent hallucinated associations. \"\n",
    "        \"4. Enforce strict validation protocols for entity resolution across multi-modal datasets.\"\n",
    "    ),\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2864a5-35a7-4ff9-8403-17269a2bbff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rounds (+ Final Round):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:   0%|          | 0/2 [00:11<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:11<00:00, 11.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 274\n",
      "Output token count: 456\n",
      "Tool token count: 0\n",
      "Max token length: 730\n",
      "Cost: $0.00\n",
      "Time: 0:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:13<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:13<00:00, 13.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 274\n",
      "Output token count: 550\n",
      "Tool token count: 0\n",
      "Max token length: 824\n",
      "Cost: $0.00\n",
      "Time: 0:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:15<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:15<00:00, 15.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 274\n",
      "Output token count: 409\n",
      "Tool token count: 0\n",
      "Max token length: 683\n",
      "Cost: $0.00\n",
      "Time: 0:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:16<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:16<00:00, 16.67s/it]\n",
      "Team:   0%|          | 0/2 [00:17<?, ?it/s]\n",
      "\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:17<00:00, 17.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 274\n",
      "Output token count: 463\n",
      "Tool token count: 0\n",
      "Max token length: 737\n",
      "Cost: $0.00\n",
      "Time: 0:18\n",
      "Input token count: 274\n",
      "Output token count: 396\n",
      "Tool token count: 0\n",
      "Max token length: 670\n",
      "Cost: $0.00\n",
      "Time: 0:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Team selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            agenda=team_selection_agenda,\n",
    "            save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b16af1-ea5a-4c4d-aa8c-b7975132b6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:21<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|██████████| 1/1 [00:21<00:00, 21.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,678\n",
      "Output token count: 794\n",
      "Tool token count: 0\n",
      "Max token length: 3,472\n",
      "Cost: $0.01\n",
      "Time: 0:22\n"
     ]
    }
   ],
   "source": [
    "# Team selection - merge\n",
    "team_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"team_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(team_selection_summaries)}\")\n",
    "\n",
    "team_selection_merge_prompt = create_merge_prompt(agenda=team_selection_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=team_selection_summaries,\n",
    "    agenda=team_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e7631-5df6-4d17-b523-efb296baeb11",
   "metadata": {},
   "source": [
    "## Projects specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64de8e97-5cdc-4473-b64f-abc227a278c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project specification - prompts (Optimized)\n",
    "\n",
    "project_specification_agenda = f\"\"\"{background_prompt}\n",
    "\n",
    "TASK: Define the Technical Specification for AlzKB.\n",
    "The team must agree on the architectural foundation before implementation.\n",
    "\n",
    "OUTPUT REQUIREMENTS:\n",
    "1. SCHEMA CORE.\n",
    "2. DATA STRATEGY.\n",
    "3. SUCCESS METRICS.\n",
    "\n",
    "CONSTRAINTS: Be specific. No fluff. Prioritize AD-specific nuances (e.g., Tau isoforms).\n",
    "\"\"\"\n",
    "\n",
    "project_specification_questions = (\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0249316-4795-43fa-8341-b086cf545135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rounds (+ Final Round):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Team: 100%|██████████| 5/5 [01:22<00:00, 16.52s/it]\n",
      "Rounds (+ Final Round):  33%|███▎      | 1/3 [01:22<02:45, 82.62s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team: 100%|██████████| 5/5 [01:24<00:00, 16.92s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Team: 100%|██████████| 5/5 [01:32<00:00, 18.43s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Team: 100%|██████████| 5/5 [01:35<00:00, 19.07s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:   0%|          | 0/5 [00:06<?, ?it/s]\n",
      "Rounds (+ Final Round):  33%|███▎      | 1/3 [01:41<03:23, 101.75s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:  20%|██        | 1/5 [00:24<01:36, 24.16s/it]\n",
      "Rounds (+ Final Round):  33%|███▎      | 1/3 [01:46<03:33, 106.78s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team: 100%|██████████| 5/5 [02:01<00:00, 24.39s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:  40%|████      | 2/5 [00:37<00:56, 18.84s/it]\n",
      "Rounds (+ Final Round):  33%|███▎      | 1/3 [02:02<04:04, 122.28s/it]\n",
      "Team:  20%|██        | 1/5 [00:34<02:19, 34.76s/it]\n",
      "Rounds (+ Final Round):  33%|███▎      | 1/3 [02:06<04:13, 126.92s/it]\n",
      "Team: 100%|██████████| 5/5 [01:56<00:00, 23.39s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:   0%|          | 0/5 [00:35<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|██████████| 3/3 [04:34<00:00, 91.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 52,515\n",
      "Output token count: 9,184\n",
      "Tool token count: 0\n",
      "Max token length: 10,454\n",
      "Cost: $0.18\n",
      "Time: 4:37\n"
     ]
    }
   ],
   "source": [
    "# Project specification - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=principal_investigator,\n",
    "            team_members=team_members,\n",
    "            agenda=project_specification_agenda,\n",
    "            agenda_questions=project_specification_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4562a7af-b01f-4e15-9b19-101ae5e8f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 2/2 [00:47<00:00, 23.76s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 2/2 [00:37<00:00, 18.59s/it]<01:35, 47.52s/it]\n",
      "Team:   0%|          | 0/2 [00:48<?, ?it/s]3 [01:24<00:41, 41.44s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 3/3 [02:13<00:00, 44.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 23,745\n",
      "Output token count: 7,601\n",
      "Tool token count: 0\n",
      "Max token length: 9,672\n",
      "Cost: $0.11\n",
      "Time: 2:15\n"
     ]
    }
   ],
   "source": [
    "# Project specification - merge\n",
    "project_specification_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"project_specification\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(project_specification_summaries)}\")\n",
    "\n",
    "project_specification_merge_prompt = create_merge_prompt(\n",
    "    agenda=project_specification_agenda,\n",
    "    agenda_questions=project_specification_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=project_specification_summaries,\n",
    "    agenda=project_specification_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47b3d6-a2b9-4a18-9af5-024648baf765",
   "metadata": {},
   "source": [
    "## Tool Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db642dbe-ceca-4a9a-9b0a-842d920ab5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prior summaries: 1\n"
     ]
    }
   ],
   "source": [
    "# Tools selection - prompts\n",
    "tools_selection_agenda = f\"\"\"{background_prompt} TASK: Select the Technology Stack for AlzKB Implementation.\n",
    "Based on the Technical Specification, decide on the best tools to handle high-precision graph data.\n",
    "\n",
    "DECISIONS REQUIRED:\n",
    "1. GRAPH DATABASE: Select 1 DB (e.g., Neo4j, ArangoDB, Neptune). Justify based on support for \"Edge Properties\" (essential for evidence scoring).\n",
    "2. AGENT FRAMEWORK: Select 1 Framework (e.g., LangGraph, AutoGen, CrewAI) that supports \"Human-in-the-loop\" (for Critic) and \"Stateful Memory\".\n",
    "3. ETL & ONTOLOGY: Select libraries for handling OBO/OWL parsing (e.g., Owlready2, rdflib).\n",
    "\n",
    "CONSTRAINT: Choose open-source/standard tools where possible to ensure reproducibility.\n",
    "\"\"\"\n",
    "\n",
    "tools_selection_questions = (\n",
    "    \"DATABASE: Select ONE primary Graph Database (e.g., Neo4j, ArangoDB, Neptune). Justify the choice based on our requirement for extensive 'Edge Properties' (Evidence Score, Provenance) and 'Vector Search' capabilities.\",\n",
    "    \"ETL STACK: Which specific Python libraries will be used for (a) Parsing Bio-Ontologies (e.g., Owlready2, rdflib) and (b) High-performance Triple Ingestion? Avoid generic answers.\",\n",
    "    \"ORCHESTRATION: Choose an Agent Framework (e.g., LangGraph, AutoGen, CrewAI). Specifically, how does it support 'Stateful Memory' (to track design iterations) and 'Human-in-the-loop' (for Gold Standard auditing)?\",\n",
    ")\n",
    "\n",
    "tools_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[discussions_phase_to_dir[\"project_specification\"] / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(tools_selection_prior_summaries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7e3d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rounds (+ Final Round):   0%|                                                                                                                                                                  | 0/2 [00:00<?, ?it/s]\n",
      "Team:   0%|                                                                                                                                                                                    | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Rounds (+ Final Round):   0%|                                                                                                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Team:   0%|                                                                                                                                                                                    | 0/5 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "Rounds (+ Final Round):   0%|                                                                                                                                                                  | 0/2 [00:08<?, ?it/s]\n",
      "Team:   0%|                                                                                                                                                                                    | 0/5 [00:19<?, ?it/s]\n",
      "Rounds (+ Final Round):   0%|                                                                                                                                                                  | 0/2 [00:19<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tools selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=principal_investigator,\n",
    "            team_members=team_members,\n",
    "            summaries=tools_selection_prior_summaries,\n",
    "            agenda=tools_selection_agenda,\n",
    "            agenda_questions=tools_selection_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=0.5,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe46747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|██████████| 2/2 [00:57<00:00, 28.84s/it]<?, ?it/s]\n",
      "Team: 100%|██████████| 2/2 [01:06<00:00, 33.09s/it]<01:55, 57.68s/it]\n",
      "Team:   0%|          | 0/2 [00:18<?, ?it/s]3 [02:03<01:02, 62.68s/it]\n",
      "Rounds (+ Final Round): 100%|██████████| 3/3 [02:22<00:00, 47.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 22,378\n",
      "Output token count: 7,231\n",
      "Tool token count: 0\n",
      "Max token length: 9,236\n",
      "Cost: $0.10\n",
      "Time: 2:23\n"
     ]
    }
   ],
   "source": [
    "# Tools selection - merge\n",
    "tools_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"tools_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(tools_selection_summaries)}\")\n",
    "\n",
    "tools_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=tools_selection_agenda,\n",
    "    agenda_questions=tools_selection_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=tools_selection_summaries,\n",
    "    agenda=tools_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88da53b",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268ff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prior summaries: 1\n"
     ]
    }
   ],
   "source": [
    "# Tools selection - prompts\n",
    "tools_selection_agenda = f\"\"\"{background_prompt} TASK: Select the Technology Stack for AlzKB Implementation.\n",
    "Based on the Technical Specification, decide on the best tools to handle high-precision graph data.\n",
    "\n",
    "DECISIONS REQUIRED:\n",
    "1. GRAPH DATABASE: Select 1 DB (e.g., Neo4j, ArangoDB, Neptune). Justify based on support for \"Edge Properties\" (essential for evidence scoring).\n",
    "2. AGENT FRAMEWORK: Select 1 Framework (e.g., LangGraph, AutoGen, CrewAI) that supports \"Human-in-the-loop\" (for Critic) and \"Stateful Memory\".\n",
    "3. ETL & ONTOLOGY: Select libraries for handling OBO/OWL parsing (e.g., Owlready2, rdflib).\n",
    "\n",
    "CONSTRAINT: Choose open-source/standard tools where possible to ensure reproducibility.\n",
    "\"\"\"\n",
    "\n",
    "tools_selection_questions = (\n",
    "    \"DATABASE: Select ONE primary Graph Database (e.g., Neo4j, ArangoDB, Neptune). Justify the choice based on our requirement for extensive 'Edge Properties' (Evidence Score, Provenance) and 'Vector Search' capabilities.\",\n",
    "    \"ETL STACK: Which specific Python libraries will be used for (a) Parsing Bio-Ontologies (e.g., Owlready2, rdflib) and (b) High-performance Triple Ingestion? Avoid generic answers.\",\n",
    "    \"ORCHESTRATION: Choose an Agent Framework (e.g., LangGraph, AutoGen, CrewAI). Specifically, how does it support 'Stateful Memory' (to track design iterations) and 'Human-in-the-loop' (for Gold Standard auditing)?\",\n",
    ")\n",
    "\n",
    "tools_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[discussions_phase_to_dir[\"project_specification\"] / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(tools_selection_prior_summaries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
